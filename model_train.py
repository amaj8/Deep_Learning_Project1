# -*- coding: utf-8 -*-
"""DL assignment

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gJlBiGfkjAyPympu_21uC-ghN4H-0H0B
"""

import torch
from torch import nn
import torch.nn.functional as F

NUM_DIGITS = 16

def decToBin(n,num_digits):
    # x = [0 for i in range(NUM_DIGITS)]
    # def recursive_fn(x,n):
    #     if n > 1:
    #         recursive_fn(x,n//2)
    #     x.append(n%2)
        
    #     return x
	
    # # return torch.IntTensor(x)
    # return recursive_fn(x,n)

    return [n >> i & 1 for i in range(num_digits)]

"""
def fizzBuzzOutput(n):
	if n%15 == 0:     return [0,0,0,1]

		# return torch.tensor([0,0,0,1])
    
	elif n%5 == 0:    return [0,0,1,0]
		# return torch.tensor([0,0,1,0])
    
	elif n%3 == 0:    return [0,1,0,0]
		# return torch.tensor([0,1,0,0])
    
	else:             return [1,0,0,0]
		# return torch.tensor([1,0,0,0])
"""

def fizzBuzzOutput(n):
	if n%15 == 0:     return 3

		# return torch.tensor([0,0,0,1])
    
	elif n%5 == 0:    return 2
		# return torch.tensor([0,0,1,0])
    
	elif n%3 == 0:    return 1
		# return torch.tensor([0,1,0,0])
    
	else:             return 0
		# return torch.tensor([1,0,0,0])

    
# x = []  
# decToBin(x,10)
# print(x)
# print(decToBin(7,NUM_DIGITS))
# print(decToBin(1023,NUM_DIGITS))

trainX = torch.Tensor([decToBin(i,NUM_DIGITS) for i in range(101,2**NUM_DIGITS)])
trainY = torch.Tensor([fizzBuzzOutput(i) for i in range (101,2**NUM_DIGITS)])

# print(trainX[0,128])
# print(trainY)

NUM_HIDDEN_UNITS = 150
# hiddenWeights = torch.rand(NUM_DIGITS, NUM_HIDDEN_UNITS)
# outputWeights = torch.rand(NUM_HIDDEN_UNITS,4)
class Network(nn.Module):
  def __init__(self):
    super().__init__()
    self.hidden = nn.Linear(NUM_DIGITS,NUM_HIDDEN_UNITS)
    self.output = nn.Linear(NUM_HIDDEN_UNITS,4)
    
  def forward(self,x):
    x = F.relu(self.hidden(x))
    x = self.output(x)
    return x
    # return F.log_softmax(x)

		# def forward(self,x):
    # x = F.relu(self.hidden(x))
		# 	x = self.output(x)
		# 	return F.log_softmax(x)		

  

net = Network()
print(net)

LEARNING_RATE = 0.01
#SGD optimizer + negative log likelihood -> cross entropy loss
optimizer = torch.optim.SGD(net.parameters(), lr = LEARNING_RATE, momentum=0.09)
loss_fn = nn.CrossEntropyLoss()

EPOCHS = 1000
BATCH_SIZE = 128
LOG_INTERVAL = 128
for epoch in range(EPOCHS):
  #shuffle the inputs at every epoch
  p = torch.randperm(len(trainX))
  trainX, trainY = trainX[p], trainY[p]

  running_loss = 0.0
  for batch_index in range(0,len(trainX),BATCH_SIZE):
    #split data into batches
    data = trainX[batch_index:batch_index+BATCH_SIZE]
    target = trainY[batch_index:batch_index+BATCH_SIZE]
    # target = target.long()

    data = torch.autograd.Variable(data)
    target = torch.autograd.Variable(target.long())

    optimizer.zero_grad()			#reset the gradients
    net_output = net(data)
    loss = loss_fn(net_output,target)
    loss.backward()					#backprop the error
    optimizer.step()				#gradient descent step based on gradients calcualated using backward() op

		
		# if batch_index % INTERVAL == 0:
		# 	print('Train Epoch#: ' + epoch + ' Batch index#: ' \
		# 		+ batch_index*len(data) + '/' + len(trainX) + \
		# 		' (' + 100. * batch_index/len(trainX) +')'  \
		# 		+ ' Loss:'+ loss.data[0])
    
    
    # running_loss += loss.item()
    # # if batch_index % LOG_INTERVAL == 0:
    # print('[%d,%5d] Loss: %.3f' %(epoch+1, batch_index+1, running_loss/LOG_INTERVAL))
    # running_loss = 0.0

#from google.colab import drive
#drive.mount('/content/gdrive')

# PATH = "network.pth"
# torch.save(net,PATH)

#network_save_name = 'network.pth'
#PATH = F"/content/gdrive/My Drive/{network_save_name}" 
# torch.save(net.state_dict(), PATH)
#torch.save(net, PATH)

# correct = 0
net = torch.load(PATH)
net_train_output = net(trainX)
_,predicted = torch.max(net_train_output.data,1)
correct = (predicted == trainY).sum()
total = trainY.size(0)
training_accuracy = 100. * correct / total
print(training_accuracy)

testX = torch.Tensor([decToBin(i,NUM_DIGITS) for i in range(101)])
testY = torch.Tensor([fizzBuzzOutput(i) for i in range(101)])

net_test_output = net(testX)
_,predicted = torch.max(net_test_output.data,1)
correct = (predicted == testY).sum()
total = testY.size(0)
test_accuracy = 100. * correct / total
print(test_accuracy)
